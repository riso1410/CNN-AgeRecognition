{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**: Richard Šléher, Tomáš Majerník"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**: https://www.kaggle.com/datasets/arashnic/faces-age-detection-dataset/code?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from summarytools import dfSummary\n",
    "from timm import create_model\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "batch_size = 256\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Máme nepomer tried, čiže pri trénovaní modelu sme nastavili rozdielne weighty pre triedy aby sme \"vyrovnali\" tento nepomer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for img_id in data[\"ID\"]:\n",
    "    img_path = os.path.join(\"data/train/\", img_id)\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            image_sizes.append(img.size)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {img_path}: {e}\")\n",
    "\n",
    "if image_sizes:\n",
    "    widths, heights = zip(*image_sizes, strict=False)\n",
    "\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.scatter(widths, heights, alpha=0.25)\n",
    "    plt.xlabel(\"Width (pixels)\")\n",
    "    plt.ylabel(\"Height (pixels)\")\n",
    "    plt.title(\"Scatter Plot of Image Sizes\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image sizes were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot distribúcie veľkostí obrázkov. Môžeme pozorovať, že obrázky majú veľký rozsah veľkostí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_intensities = []\n",
    "\n",
    "for img_id in data[\"ID\"]:\n",
    "    img_path = os.path.join(\"data/train/\", img_id)\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            grayscale_img = img.convert(\"L\")\n",
    "            pixel_intensities.append(np.array(grayscale_img).flatten())\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {img_path}: {e}\")\n",
    "\n",
    "if pixel_intensities:\n",
    "    combined_intensities = np.concatenate(pixel_intensities)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(\n",
    "        combined_intensities,\n",
    "        vert=False,\n",
    "        patch_artist=True,\n",
    "        boxprops={\"facecolor\": \"lightblue\"},\n",
    "    )\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.title(\"Box Plot of Pixel Intensities\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No pixel intensities were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = plt.imread(\"data/train/\" + data.iloc[i][\"ID\"])\n",
    "    plt.imshow(img)\n",
    "    plt.title(data.iloc[i][\"Class\"])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"ID\"]\n",
    "y = data[\"Class\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_train_df[\"Target\"] = y\n",
    "dfSummary(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_test_df[\"Target\"] = y_test\n",
    "dfSummary(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_df = pd.DataFrame(X_val)\n",
    "X_val_df[\"Target\"] = y_val\n",
    "dfSummary(X_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "\n",
    "for filename in os.listdir(\"./data/Train/\"):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(\"./data/Train/\", filename)\n",
    "        with Image.open(image_path) as image:\n",
    "            image_data.append(\n",
    "                {\n",
    "                    \"filename\": filename,\n",
    "                    \"width\": image.width,\n",
    "                    \"height\": image.height,\n",
    "                    \"mode\": image.mode,\n",
    "                    \"image\": image,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df = pd.DataFrame(image_data)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Width Stats:\")\n",
    "print(df[\"width\"].describe())\n",
    "print(\"Height Stats:\")\n",
    "print(df[\"height\"].describe())\n",
    "\n",
    "df[\"aspect_ratio\"] = df[\"width\"] / df[\"height\"]\n",
    "print(\"Aspect Ratio Stats:\")\n",
    "print(df[\"aspect_ratio\"].describe())\n",
    "\n",
    "print(\"Image Modes Count:\")\n",
    "print(df[\"mode\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, filenames: str, labels: str, transform: transforms.Compose=None) -> None:\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {\"YOUNG\": 0, \"MIDDLE\": 1, \"OLD\": 2}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        img_name = os.path.join(\"data/train/\", self.filenames.iloc[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = self.labels.iloc[idx]\n",
    "        label = self.label_mapping[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = AgeDataset(filenames=X_train, labels=y_train, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = AgeDataset(filenames=X_val, labels=y_val, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = AgeDataset(filenames=X_test, labels=y_test, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dané transofrmácie sme vybrali na základe toho, že sa najviac hodia na normalizáciu násho typu obrázkov. Pretože, keď máme tvár nemôžeme ju otočiť napr. o 180 stupňov, lebo by si daný model mýlil oči s ústami napríklad. Horizontal flip a color jitter sú mierne transformácie aby sa model nenaučil iba na jeden uhol alebo jednu farbu pleti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voľba modelov\n",
    "\n",
    "1.\n",
    "- modifikovaná verzia LeNet-5 s pridanou batch normalizáciou\n",
    "- jednoduchá architektúra pridali sme batch norm aby sme redukovali overfitting\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        s = self.dropout3(x)\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels=3, num_classes=3).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: CNN, val_loader: DataLoader, criterion: nn.CrossEntropyLoss) -> tuple:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average=\"weighted\")\n",
    "    recall = recall_score(all_labels, all_predictions, average=\"weighted\")\n",
    "    f1 = f1_score(all_labels, all_predictions, average=\"weighted\")\n",
    "\n",
    "    return val_loss / len(val_loader), accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([1.0, 2.0, 3.0]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"age-recognition\",\n",
    "    name=\"Custom-CNN\",\n",
    "    config={\n",
    "        \"model\": \"Custom-CNN\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": num_epochs\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.to(device)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    val_loss, val_accuracy, precision, recall, f1 = evaluate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"f1\": f1,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f},\\\n",
    "    Train Accuracy: {train_accuracy:.3f}, Val Accuracy: {val_accuracy:.3f},\\\n",
    "    Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\"\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "wandb.finish()\n",
    "torch.save(model.state_dict(), \"CNN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z výsledkov vidíme, že sa nám prestal zlepšovať model približne od 20 epochu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = create_model(\"xception\", pretrained=True, num_classes=0)\n",
    "conv_base.global_pool = nn.Identity()\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = conv_base\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.batch_norm1 = nn.BatchNorm1d(2048)\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.output(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "model = CustomModel(num_classes=num_classes).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "class_weights = torch.tensor([1.0, 2.0, 3.0]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"age-recognition\",\n",
    "    name=\"Custom-CNN_Xception\",\n",
    "    config={\n",
    "        \"model\": \"Custom-CNN_Xception\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": num_epochs-40\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs-40):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    val_loss, val_accuracy, precision, recall, f1 = evaluate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"f1\": f1,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f},\\\n",
    "    Train Accuracy: {train_accuracy:.3f}, Val Accuracy: {val_accuracy:.3f},\\\n",
    "    Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\"\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "wandb.finish()\n",
    "torch.save(model.state_dict(), \"CNN_Xception.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z výsledkov vidíme..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resnet-18 - pretrained\n",
    "\n",
    "Source: https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = models.resnet18(pretrained=True)\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 3)\n",
    "\n",
    "model = model_resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"age-recognition\",\n",
    "    name=\"Resnet-18\",\n",
    "    config={\n",
    "        \"model\": \"Resnet-18\",\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": num_epochs-40\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs-40):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    val_loss, val_accuracy, precision, recall, f1 = evaluate(\n",
    "        model, val_loader, criterion\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"f1\": f1,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f},\\\n",
    "    Train Accuracy: {train_accuracy:.3f}, Val Accuracy: {val_accuracy:.3f},\\\n",
    "    Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\"\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "wandb.finish()\n",
    "torch.save(model.state_dict(), \"resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z výsledkov vidíme..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our face prediction using Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, transform, device):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\"riso.jpg\", \"tomas.jpg\"]\n",
    "predictions = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    prediction = predict_image(model, image_path, transform, device)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "label_mapping = {0: \"YOUNG\", 1: \"MIDDLE\", 2: \"OLD\"}\n",
    "\n",
    "for ax, image_path, prediction in zip(axes, image_paths, predictions, strict=False):\n",
    "    image = plt.imread(image_path)\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f\"Prediction: {label_mapping[prediction]}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
